\section{Implementering}\label{sec:deadline-implementation}
\fxwarning{metatekst goddammit!!}
\subsubsection{Overskredne deadlines}
Planlægning i realtime kræver at man tager stilling til, hvordan  overskredne deadlines skal håndteres. Enten kan det opfattes som en egenskab for processen hvor dens deadline enten kan være overholdt eller ej, eller også kan en overskreden deadline resultere i en exception.

Hvilken metode, der egner sig bedst til RTP, afhænger af hvilken deadline, der er tilknyttet processen. Er der tilknyttet en soft deadline til en proces, vil processen stadig tilføje værdi til systemet, selvom det overskrider dens deadline. Derfor kan det stadig være bedst for systemet at fuldføre processen til ende. I dette tilfælde  skal systemet blot markere at dens deadline er overskredet, og senere må programmøren så manuelt håndtere den overskredne deadline. 

Hvis en proces har tilknyttet  en hard deadline, vil en overskredet deadline ikke tilføje værdi til systemet, og derfor kan det ikke betale sig for systemet at lade processen blive færdig. Processen skal derfor stoppes hurtigst muligt, så systemet i stedet kan udføre de processer hvis deadline endnu ikke er overskredet. For et system, hvor processerne har hard deadlines, vil det derfor være bedst, hvis en overskredet deadline resulterer i en exception, der med det samme stopper processen, og lader programmøren bestemme hvordan processen skal forholde sig til at deadlinen er overskredet.

Vi har valgt, at der i vores system skal kaldes en exception, hvis en deadline overskrides. Dette er gjort ud fra en betragtning om, at systemet ikke kender konsekvensen af en overskredet deadline, men på processniveau har udvikleren tilføjet en deadline, og derfor må det være udviklerens ansvar at håndtere processen ved en overskridelse af deadline.  Hvis processen stadig kan bidrage med værdi, kan programmøren lade processen fortsætte sin kørsel. Alternativt kan processen lukkes korrekt ned. Ulempen ved at kalde en exception er, at processen stopper sin eksekvering i utide, hvilket kan give problemer, f.eks. hvis processen er tilknyttet en kanal og venter på at kommunikere.  Kanalerne holder i \pycsp styr på antallet af processer, der vil kommunikere, og hvis processen pludseligt forsvinder vil tilstandsvariablerne ikke være sat korrekt. Det er derfor vigtigt at processen manuelt rydder op efter sig selv i forbindelse med en exception, da det ellers kan resultere i et ustabilt system.\fxwarning{det sker automatisk, ikke manuelt}
\fxwarning{Skriv mere om hvordan vi håndterer de interne variable inden vi kaster en exception til udvikleren}

I en fremtidig version ville man kunne udvide muligheden med en hybridversion, der skulle kunne håndtere processer med soft deadlines, der skal markeres, og kalde exceptions ved processer med hard deadline. Processen kunne f.eks have tilknyttet dens type af deadline. Systemet kan så reagere passende efter typen af deadlines, så soft deadlines blev færdigbehandlet, mens hard deadlines resulterede i en exception.


\subsubsection{Ændringer i \sched en}
I \code{greenlets} versionen af \sched en findes der som nævnt i \cref{sec:scheduler} tre lister af processer: \code{new}, \code{next} og \code{timers}. De tre lister er prioriteret således, at der først kigges på processer fra \code{timers}, dernæst fra \code{new} og til sidst kigges der i \code{Next}.

I RTP er det ikke hensigtsmæssigt at inddele processerne i disse tre  kategorier. Vi skal derimod have et miljø, der gnidningsløst tillader processer både med og uden deadlines, samt at de dynamisk kan ændres. Skemaplanlæggeren skal i forbindelse med processkift hurtigt kunne finde den næste proces, der skal udføres.

Vi har derfor valgt at fjerne  de tre lister og erstatte dem  med \code{has"_priority},  \code{no"_priority} og \code{timers}. \code{has"_priority} og  \code{no"_priority}  bruges til at placere  aktive processer der ønsker, at blive udført, mens  \code{timers} er en kopi af \des versionen. 

Det er vigtigt at bemærke ifht. processer der ligger i \code{timers}, at udvikleren ikke kan forvente at de bliver aktiveret på de eksakte tidspunkt han har defineret. Dette er kun muligt i \des versionen hvor vi kan kontrollere tiden. Den eneste garanti der gives, når vi arbejder med realtid, er at de tidligst aktiveres på det angivne tidspunkt. I \code{greenlets}-versionen  aktiveres først processer fra \code{timers} listen, for at minimere overskridelsen fra processen afgiver kontrol til den igen er aktiveret. På denne måde emuleres, at processen venter i præcist det tidsrum man har angivet for så at fortsætte. I RTP antess det, at der findes en mængde processer, der skal gennemføres inden en deadline, hvorfor de må kæmpe om CPU-tid. En proces, der har ventet i \code{timers} listen skal derfor ikke nødvendigvis udføres med det samme, da det hele tiden bør være den proces med den højeste prioritet der skal udføres, uafhængigt af processerne i \code{timers} hoben. Processerne, der ikke længere skal ligge i timeout, bliver derfor planlagt og udvalgt på lige fod med andre processer der er klar til at blive udført. 

Til at implementere \code{has"_priority} bruger vi også en hob, men da modulet \code{heapq} kun understøtter min-hobe kan vi ikke lave en klassisk prioritetshob, da den skal kunne udtrække processen med maksimal prioritet. Vi har dermed to muligheder, enten kan vi lave vores egen implementering af en maks-hob, eller også kan vi ændre vores prioriteter internt, så en lav værdi angiver en høj prioritet. Med en egen implementering har vi en  logisk opbygning af prioriteter, men vi får ikke fordelen ved den underliggende implementering  direkte i C, som man opnår ved brug af modulet heapq. Vælger vi at bruge dette, skal vi invertere prioritetsbegrebet, så det er den laveste prioritet, der udvælges først. Dette viser  sig dog ikke at være et problem  i vores tilfælde, da vi ønsker at benytte os af en EDF algoritme og derfor nemt kan opnå den ønskede effekt ved at bruge en proces' deadline som dens prioritet. Her vil en lav deadline betyde, at processen snart skal være færdig, hvilket resulterer i en høj prioritet.
Vi kan derfor blot benytte en proces' deadline som dens prioritet og benytte en min-hob. 

%Hvis man i en fremtidig version ønsker at udvide vores \sched , så en udvikler kan tilknytte bruger-prioriteter til proceserne, kan det f.eks implementeres ved efterfølgende at ændre \sched ens prioritet. Dette vil resultere i at processen bliver opprioriteret ifh. til andre processer.

\subsubsection{Preempting}

Som vi har beskrevet i \cref{sec:rtp-pycsp}, kan  man risikere at en proces med lav prioritet proces og lang kørselstid kan blokere for en proces med høj prioritet. 
Her konkluderede vi at det er programmørens opgave at processen afgiver kontrol, og derfor skal det være nemt at afgive kontrollen fra processen. til dette har vi lavet funktionen \code{Release()}, der minder om \code{Yield} for \code{co-rutiner}.

Implementeringen er meget simpel og er blot en wrapperfunktion, da den underliggende funktionalitet allerede eksisterer. Den aktive proces stopper og bliver genplanlagt til senere kørsel af \sched en. Dermed ligges processen på den relevante kø og  \sched en  kan blot vælge  den bedst proces der skal udføres. Er  der ikke kommet ny processer vil det stadigt være den originale proces der udføres og kan fortsætte sin kørsel. Hvis der derimod i mellemtiden er ankommet en eller flere nye processer der har højere prioritet, vil disse blive udført i stedet.

Problemet ved denne tvungne procesafgivelse er at det kan tage lang tid at blive lagt korrekt i en min\_hob, som vil være spildt hvis den alligevel med det samme fjernes fra køen. Man vil derfor nok i en senere version kunne optimere hastigheden af \code{Release()}.


\subsubsection{Udvidelse af \code{Process}}

Hver proces skal have mulighed for at få tilknyttet en deadline, og desuden skal det være muligt i forbindelse med prioritetsnedarvning midlertidigt at kunne ændre dens prioritet til en kunstig prioritet.

Når en proces bliver udsat for prioritetsnedarvning, skal systemet planlægge processen ifh. til den nye kunstige prioritet. Men det er ikke defineret om den kunstige prioritet medfører at systemet kaster en  \code{deadlineException},  hvis  denne overskrides. Ved at kaste en \code{deadlineException} i processer med kunstig prioritet, kan programmøren se præcist hvilken proces der arbejder, og dermed bedre debugge hvorfor den originale proces også kaster en \code{deadlineException}. \Cref{fig:producer-worker-consumer} viser at med en \code{deadlineException} vil det tydeligt fremgå at det er $B2$ der bære skylden for at deadlinen ikke overholdes.

En anden begrundelse for at lade en kunstig prioritet medføre en \code{deadlineException}, er hvis processerne findes i et generator/arbejder/forbruger-netværk, som vist i \cref{fig:producer-worker-consumer}. Her tilføjes forbrugeren og generatoren for den kunstige prioritet. Hvis denne deadline ikke nås er dataen som arbejderen bearbejde ikke længere relevant og arbejderen bør derfor stoppe det irrelevante arbejde snarest. Dette ville medfører at $B_2$ kunne stoppe sit arbejde i til $t = 5$ i modsætning til at fortsætte til $t = 6$.



\begin{figure}
 \begin{center}
  \includegraphics[scale=1.00]{images/producer-worker-consumer}
  \caption{Et generator/arbejder/forbruger -netværk. De stiplede pile i proces $B_1$ og $B_2$ til $t=5$ viser en kunstig prioritet på baggrund af $B_3$'s deadline. Den lille stiplede pil mellem  $B_1$ og $B_2$ i $t=2$ og mellem $B_2$ og $B_3$ i $t=6$ viser kommunikation mellem processerne.}
  \label{fig:producer-worker-consumer}
  \end{center}
\end{figure}

\begin{figure}
 \begin{center}
  \includegraphics[scale=1.00]{images/producer-worker-consumer2}
  \caption{Samme netværk som i \autoref{fig:producer-worker-consumer}, men i dette tilfælde venter $B_2$  på data fra $B_1$ i hovedparten af tiden inden en deadline.}
  \label{fig:producer-worker-consumer2}
  \end{center}
\end{figure}


Der er dog flere problemer ved at lade en kunstig prioritet medføre en \code{deadlineException}.  Til at hjælpe programmøren,  er det ikke givet at den proces der overskrider en deadline, er den der har brugt tiden. \CRef{fig:producer-worker-consumer2} viser næsten netværk som før,men i dette tilfælde bliver data først sendt fra $B_1$ umiddelbart før en overskridelse af deadline. Her vil det fremgå for programmøren  at det er $B_2$ der er ansvarlig for overskridelsen og ikke $B_1$. Dermed mister \code{deadlineException} sin troværdighed til debugging. I CSP findes desuden begrebet traces, som kan bruges til at se hele forløbet for et program. På nuværende tidspunkt arbejdes der med at introducere traces til \pycsp og når dette er færdigt, vil det være et langt at foretrække som værktøj til debugging.

Et andet problem ved at kaste en \code{deadlineException} ved kunstigt lave prioriteter, er at processer måske  ikke er designet med hensyn til en mulig \code{deadlineException}. Programmøren skal dermed sikrer alle sine processer, hvis ikke hele processen skal risikere at stoppe ved en exception der ikke bliver hånteret korrekt. Begrundelsen for en deadline, og den tilhørende \code{deadlineException}, er kontekstafhængig, og  det er ikke sikkert processen kender begrundelsen for en given deadline, og vil  ikke kunne reagere optimalt. Eksempelvis  vil $B_2$ fra eksemplerne, ikke uden  forhåndsvidden kunne foretage valget om en \code{deadlineException} betyder den skal sende sit arbejde uafhængigt af hvor langt den er kommet. Stoppe arbejdet til den bliver bedt om at fortsætte. eller smide arbejdet ud og starte bearbejdningen af nyt data.

Vi har derfor valgt at det kun er processer med en eksplicit deadline, der har mulighed for at kaste en \code{deadlineException}. Processer der nedaver en prioritet bliver planlagt i henhold til den højeste prioritet de har, og vil altid  gøre arbejdet færdigt. En proces skal dermed kunne adskille sin egen deadline fra den prioritet som den skal planlægges med, til trods for de to tal i en stor del af tiden vil være det samme.

Vi har valgt at udvide procesmodellen med variablen \code{deadline}, der indeholder den specifikke deadline for processen, og som dikterer om der skal kastes en 
\code{deadlineException}. Desuden tilføjer vi listen \code{inherit\_priotity}, som indeholder de aktuelle prioriteter for processen. Når andre processer ønsker midlertidigt at ændre en proces prioritet, tilføjes den listen. Ved at bruge en liste i stedet for blot en variable, har processen mulighed for at blive opprioriteret flere gange, og vende tilbage den oprindelige prioritet efterfølgende. Når en proces får en eksplicit deadline, tilføjes denne værdi også til listen, som dens startprioritet. 

Når \sched en placere processen i sin bob bruges blot den mindste prioritet i listen ihh. til vores implementering af \sched en. Dette medfører  at når en proces efterfølgende  får ændret i sin liste af prioriteter skal processen genplanlægges for at sikre den står på den korrekte plads i min-hoben i \sched en. 

\subsubsection*{Kanaler}
I \pycsp findes der kun kanaler af type \code{Any-To-Any} og derfor kan der altid  være et vilkårligt antal kanalender i hver enden af kanalen, der måske er klar til at kommunikere. Vi skal derfor ændre koden, således at kommunikationen mellem kanalenderne altid foregår mellem de højst prioriterede processer. 

I greenletsversionen foregår udvælgelsen af kanalender til kommunikation ved hjælp af funktionen \code{match}, der udnytter at  hver kanal vedligeholder to lister af processer for hhv. de processer der ønsker at sende og modtage data på kanalen. Når en proces eks. ønsker at modtage data tilføjer den sig selv til listen af processer der ønsker at modtage, og prøver derefter i \code{match} funktionen at finde en proces der vil sende data. Er der ingen processer der venter på at sende data, venter processen selv  på at en proces melder sig klar til at sende data, og som så vil kalde \code{match}. Til hver vellykket kommunikation af data vil \code{match} altid blive kaldt to gange, hvor kun den sidste vil resultere i at kommunikationen lykkedes.

Ideen bag funktionen \code{match} er enkel og  udnytter at greenletsversionen er enkelttrådet så hver proces kan løbe listerne igennem uden andre processer ændre på listernes tilstand.  Vi er kommet frem til at  en simpel sortering af listerne, med hensyn til deres interne prioritet vil resultere i det altid er den højst prioriterede proces der indgår i kommunikationen. Den ændrede match kan ses i \cref{lst:match}, hvor det kun er linje 119 og 120 der er ændret.

\begin{lstlisting}[firstnumber=117 ,float=hbtp, label=lst:match, caption=funktionen \code{match} der sorterer kanalrequests.]
def match(self):        
    if self.readqueue and self.writequeue:
        self.readqueue.sort(key=lambda channelReq:channelReq.process.internal_priority)
        self.writequeue.sort(key=lambda channelReq:channelReq.process.internal_priority)
        for w in self.writequeue:
            for r in self.readqueue:
                if w.offer(r):
                    return       
\end{lstlisting}

Funktionen \code{match} vil blive kaldt en gang for hver proces der ønsker at kommunikere, og derfor vil listerne til hvert kald af \code{match} være totalt sorteret minus det sidste element i listen. Desuden vil der altid i den ene liste maksimalt være et element der er aktiv, hvorfor den ene liste højst sandsynlig vil være kort kørselstiden for de to sorteringer vil derfor være lille. Bemærk desuden at listerne er sorteret så værdien af den interne prioritet er stigende, og derfor er det processen med lavest værdi, der først bliver udvalgt til et match, i overensstemmelse med repræsentationen af prioriteter som nævnt i afsnittet ``Ændringer i \sched en''.

\subsubsection*{Alternation}

Som nævnt i afsnit \cref{misc:kanal-prioritet} har vi behov for at kunne tilknytte en prioritet til en kanal for at kunne håndtere udvælgelse i \code{alternations}. Vi har allerede prioriteter for processer, og ønsker  kanalernes prioritet skal defineres på baggrund af hvilke processer der er tilknyttet kanalen. Da prioriteten af en kanal skal bruges til udvælgelse i en \code{alternation} er der forskel på om udvælgelsen sker på baggrund af en  input- eller output-guard. Derfor ønsker vi at tilknytte to prioriteter til hver kanal.  De to prioriteter er sat som  den højst prioriterede proces i hver kanal der er klar til at hhv. modtage og sende data.En kanals prioritet er derfor ikke fast som for processerne, hvor de får sat en prioritet (der dog kan ændres med prioritetsnedarvning), men mere en emuleret prioritet som ændre sig baseret på alle processernes tilstand. 

Til at implementere de to prioriteter introduceres  to hjælpefunktioner der løber hhv. \code{readqueue} og \code{writequeue} igennem og  finder den højst prioriterede proces der er villig til hhv. at sende og modtage data. Når  \code{alternation} ønsker at finde prioriteten for en kanal, kigger den på om kanalen i \code{alternation} er tilknyttet en output eller inputguard og finder den korrekte prioritet.


\subsubsection*{Prioritetsnedarvning}
Prioritet i et RTP system skal ses i forhold til alle processers prioritet. En proces kan derfor ikke i sig selv have en absolut høj prioritet, men kun have høj prioritet ifh. til de andre processers prioritet. Ved at give en høj prioritet til  en proces, vil dette dermed  indirekte sænke de andre processers prioritet, et fænomen vi vil kalde prioritetsdevaluering.

For at minimere prioritetsdevaluering i forbindelse med prioritetsnedarvning  ønsker vi, at minimere tiden en proces har en kunstigt høj prioritet og minimere antallet af processers, hvis prioritet øges. 

Som vi er kommet frem til i \cref{sec:rtp-pycsp-nedarvning}, skal  der foregå  prioritetsnedarvning i forbindelse med kommunikation, hvis der ikke finder nogle processer der umiddelbart er klar til at kommunikere.  I \pycsp kan man umiddelbart evaluere om der er processer klar til at kommunikere over en given kanal. Det skyldes at processer der ønsker kommunikation befinder sig i listerne \code{readqueue} og \code{writequeue}. Hvis ingen proces ønsker at kommunikere, kan man dog ikke finde de processer som potentielt kan indgå i kommunikation.
Vi må derfor udvide kanalerne i RTP versionen, med to lister, \code{readerprocesses} og \code{writerprocesses}, der består af de processer der potentielt kan sende og modtage data over kanalen. 
Det er dog ikke ummidelbart hvordan kanalerne skal udfylde de to lister, da processerne dynamiske starter og stopper, og antallet af processer tilknyttet en given kanal varierer over dens levetid.
Dette kan løser vi ved at hver proces ved opstart tilføjer sig selv til de kanaler den har mulighed for at kommunikere over. Et oplagt sted at implementere denne funktionalitet er i processens  \code{\_\_init\_\_}  funktion. Til det skyldes at alle kanalender som denne proces potentielt kan kommunikere over, findes som argument til  \code{\_\_init\_\_} funktion. \Cref{lst:process-init} viser udvidelsen af funktionen, hvor argumenterne gennemløbes mens der ledes efter kanaler som processen skal registreres i.

\begin{lstlisting}[firstnumber=29 ,float=hbtp, label=lst:process-init, caption=Uddrag af \code{Process}' \code{\_\_init\_\_}funktion]
for arg in args:
    if isinstance(arg, pycsp.greenlets.channelend.ChannelEndRead):
        arg.channel._addReaderProcess(self)
    if isinstance(arg, pycsp.greenlets.channelend.ChannelEndWrite):
        arg.channel._addWriterProcess(self)  
\end{lstlisting}

Kanaler kender nu  både de processer der på et specifikt tidspunkt ønsker at kommunikere via listerne \code{readqueue} og \code{writequeue}, samt de processer der potentielt vil kunne kommunikere med listerne \code{readerprocesses} og \code{writerprocesses}. En proces der ønsker at kommunikere over en kanal, kan nu  både evaluere om den umiddelbart kan kommunikere, og hvis ikke hvilke processers  prioritet den kan øge for at komme til at kommunikere.

Implemtenteringen af prioritetsnedarvning, skal implementeres i de to interne kommunikationfunktioner  \code{\_read} og \code{\_write}. Fordelen ved at placere prioritetsnedarvning i disse to funktioner er at de bruges både i forbindelse med normal blokerende kommunikation, af processerne, samt i forbindelse med kommunikation i \code{alternation}. Vi har udvidet funktionerne med følgende liste af begivenheder:
\begin{itemize}
\tightlist
	\item Undersøg om processen opfylder kriterierne for at starte en prioritetsnedarvning.
	\item Forhøj prioriteterne for de potentielle processer i enten \code{readerprocesses} eller \code{writer\-processes}.
	\item Umiddelbart efter kommunikationen nedprioriteres de processer, man midlertidigt har øget prioriteterne på.
\end{itemize}

som beskrevet er det vigtigt vi igennem hele designet forsøger at begrænse mængden af prioritetsnedarvningen, og derfor har vi tilføjet en række egenskaber  der skal være indfriet før prioritetsnedarvningen forsøges. Disse er: processen skal have en prioritet, enten direkte eller efter en nedarvning; kanalen må ikke være klar til kommunikation, hvilket vil sige at ønsker processen at skrive må der ikke findes en proces der er klar til at modtage data; endelige skal processen ikke have overskredet sin egen deadline, da denne tilslut blot vil genererer en exception, og hele prioritetsnedarvningen vil være irrelevant.

Selve prioritetsforhøjelsen og den senere nedprioritering er simpel da processen blot sender sin prioritet til alle processerne i den relevante liste dvs. \code{writerprocesses} for  \code{\_read} funktionen og vice versa. Hvis en proces modtagere en lavere prioritet end den endelige prioritet ses der bort fra hhv. op- og nedjusteringen, så en prioritetsnedarvning ikke resulterer i en forringelse af prioritet. 

