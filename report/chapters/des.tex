\chapter{\Des}
\inline{sammenligning af simulation vs. modellering.\\
  simulering er en implementation af modellen.\\
  styrke er samspillet mellem flere elementer/modeller.\\
  simulering - dynamisk - tid (time/space).} 

Simuleringer har længe været et værdifuldt værktøj til at klarlægge hvordan et 
system fungerer og er specielt brugbart til at repræsentere systemer hvis 
tilstand ændres over tid, eller såfremt der er interaktion mellem flere systemer. En 
matematisk model af disse systemer vil ofte være væsentligt mere kompleks og 
kan være svær at overskue lige så let som en simulering af samme system. 

Simuleringer foretages ofte af andre videnskabsfolk end dataloger, og det er 
derfor vigtigt at de kan repræsenteres i et sprog som er let tilgængeligt og 
minimerer sandsynligheden for at begå fejl i konstruktionen af simulationen.  
Til dette formål er programmeringssproget Python oplagt da det netop fokuserer 
på let tilgængelighed og høj produktivitet for udvikleren. 

Det er oplagt at benytte CSP\cite{hoare-csp} til at repræsentere en simulering.  
I CSP er interaktionen mellem forskellige processer/systemer eksplicit, og på 
grund af modulariteten er det nemt at konstruere komplekse systemer ud fra 
mindre enkle systemer. 

\section{Beskrivelse/teori} \label{sec:des-teori}
\inline{Beskrivelse af tidsmodellen, teorien omkring den og hvor/hvad den 
    benyttes til. Teori: henvisning til litteratur, bl.a.  matematik/beviser 
    for modellen}
\inline{Noget med hvilke funktion der er krævet. (Kun en Wait og en Now)}


Indenfor simulering er \des en meget brugt metode til at modellere systemer. I 
\des anskues tid som diskrete tidsskridt som er uden kobling til realtid. I 
disse tidsskridt udføres en eller flere begivenheder, som ved afslutning kan 
føre det modellerede system over i en ny tilstand, og herved et nyt tidsskridt. 
Det er irrelevant hvor lang tid det tager at udføre en begivenhed målt i 
realtid, der sker først en overgang til en ny tilstand når alle begivenheder 
for et givet diskret tidsskridt er udført. Dette er årsagen til at der ikke er 
nogen kobling mellem den diskrete tid og realtid, og et diskret tidsskridt kan 
variere arbitrært i realtid. Begivenhederne der skal udføres af systemet kan 
enten være givet på forhånd, eller blive skemaplanlagt dynamisk af andre 
begivenheder. 


begivenheder - liste - statisk, dynamisk skemalægning 
stokastisk varians


målepunkter - brugbare data - hvad kan vi få af information: kølængde, 
gennemsnitlig/min/max behandlingstid, 
fordele


forklaring af hvad DES er
Beskriv modellen - tilstande, overgange, diskrete tidsskridt(events i sig selv 
tager ikke tid, tiden tikker mellem events)
Hvad bruges DES til? styrker/svagheder?
Henvis til DE-simulation.ps

\subsection{Barrierer} \label{sec:barrierer}
\fxnote*{RS: Jeg synes det er forkert at starte et afsnit med ``I modsætning 
til\ldots'' når det ikke er en reference til noget ovenstående}{I \des findes 
der i modsætningen til Parallel \des} \fixme{referencer} en 
global tid og alle processerne skal derfor have en fælles tid der tæller op 
samtidigt.  En global viden som tid kræver synkronisering af alle 
processerne\fxnote{ref}, og til denne koordinering og synkronisering af flere 
processer er den mest brugte metode at introducere en barriere.

Barrierer blev først introduceret i MPI\fxnote{ref}, hvor den bruges til at 
sikre at alle tråde venter i barrieren før de kan fortsætte. 

I \fxnote*{RS: Gælder vel generelt for CSP}{\pycsp} kan man udnytte at begge 
kanalender skal være klar, før der der kan kommunikeres og at en proces der er 
indgår i en kommunikation vil vente indtil den anden ende er klar før den 
fortsætter.  Ved hjælp af kanaler kan man derfor lave en simpel barriere 
trivielt ved brug af kommunikation over kanaler.  En implementering af en 
barriere som en selvstændig proces kan eksempelvis implementeres som i 
\cref{barrier-imp}.

\begin{lstlisting}[float, label=barrier-imp,caption=En barriere i \pycsp]
@proces
def Barrier(nprocesses, signalIN, signalOUT):
	while True:
		for i in range (nprocesses):
			signalIN()
		for i in range (nprocesses):
			signalOUT(0)
\end{lstlisting}

Denne implementering af en barriere kræver, i modsætning til de fleste andre 
implementeringer af barrierer\cites{mpi-barrier, crew}, to kald. Det første 
sender en variabel til barriereprocessen, mens,
det andet kald modtager en dummyværdi fra barriereprocessen. Det kræver derved 
to kanaler at implementere barrieren. På den ene kanal er barrieren den eneste 
der læser værdierne; en besked sendt på denne kanal vil derfor altid modtages 
af barrieren. På den anden kanal er barrieren den eneste der skriver, og en 
modtaget besked må derfor komme fra barrieren.

Vi kan overbevise os om korrektheden af barrieren, da alle processerne først 
går ind i barrieren ved at sende en værdi til barrieren. Hvis barrieren ikke er 
klar, sikrer \csp at processerne venter indtil barrieren er klar til at modtage 
værdierne. Først når barrieren har modtaget en værdi fra alle processerne, 
begynder barrieren at sende sin værdi, og det er først når en proces modtager 
denne værdi fra barrieren at den må fortsætte. Når en proces modtager værdien 
fra barrieren fortsætter den og man kan risikere at den ønsker at gå ind i 
barrieren inden denne har sendt sin værdi til alle processerfor at frigive dem.
Processer der ønsker adgang til barrieren vil da gå i stå, idet de prøver at 
sende til barrieren før den er klar til at modtage på den givne kanal. Først 
når barrieren har signaleret til alle processer at de må fortsætte, læser den 
på kanalen for at accepterer processer der ønsker at tilgå barrieren. Det er 
denne egenskab fra \csp der giver os garanti for at en proces der netop er 
frigivet fra barrieren ikke går ind i den igen og derved risikerer at komme 
foran. 



En ulempe ved denne simple barriere er at antallet af processer skal være 
konstant gennem hele kørslen.
Dette er f.eks. et problem i bankeksemplet (\cref{bank-eksempel}), hvor 
generatorfunktionen kan slutte lige efter at have genereret den sidste kunde.  
Her må den fortsætte med blot at kalde barrieren, indtil servicedisken har 
processeret alle kunderne, før hele programmet kan afslutte. Alternativt må 
barriereprocessen ændres, så den dynamisk kan ændre på hvor mange processer der 
skal synkroniseres. \inline{skal vi fortælle hvordan der kan gøres i \pycsp}
\fxnote{RS: Reference frem i teksten til eksempler der endnu ikke er introduceret}


Barrierer er en meget effektiv metode til at synkronisere processer der kører 
parallelt, og er brugt flittigt i MPI. I \csp er der dog en konflikt i brugen 
af barrierer da hver proces fungerer i isolation, og den eneste interaktion der 
skal være mellem processerne er når der kommunikeres via kanalerne. 
Introduktionen af barrierer og kald til disse virker derfor kunstig i \csp. 
\citeauthor{crew} beskriver brugen af barrierer som:

\mycite[1]{crew}{
\begin{otherlanguage}{english}
[\ldots] where the barriers may be used to maintain global and/or localised models of time and to synchronise safe access to shared data [\ldots]
\end{otherlanguage}
}

Barrierens berettigelse er derfor for at kunne introducere tid, samt for at kunne bruge delt data. I \csp bør der ikke være delt data mellem processerne, men derimod kun  lokalt data. Hvis der er data er delt pga. arkitekturen \csp er implementeret på, bør dette abstraheres væk men udnyttes internt i kanalerne. At introducere hjælpemidler for styre delt data, er derfor at tilskynde til en forkert brug af \csp. Tiden er den anden begrundelse for at benytte barrierer.\fxnote*{Skal hives et niveau op tekstmæssigt}{Men med brugen af barrierer til at modellerer tid, kan man får  en primitiv model for tid, og vi vil i vores speciale vise ved at inkluderer tid i stedet får man et stærkere værktøj der ud over en masse andet også kan erstatte brugen af barrierer.}


\subsection{Timeout} 
\inline{kausal tid.}
Med et simuleringsmiljø er det ikke nok
udelukkende kan kunne specifiere en timeout på kanalen ud i fremtiden,
det er også nødvendigt at man kan specificere at en proces er villig
til at kommunikere på et specifikt tidspunkt, samt at den kanalen
villig til at kommunikere på nuværende tidpunkt, men ikke ud i
fremtiden.

At ville kommunikere fra et given tidspunkt i fremtiden, svare til at   
vente uden at lave noget indtil det givne tidspunkt for så at forsøge 
at kommunikere fra tidpunktet indtil kommunktationen lykedes. Dette     
kan dermed laves helt uden en alternation, men ved blot med de to       
funktioner Wait(time), Cin().                                           

At ville være villig til at kommuikere til et given tidspunkt,         
medfører en ny problemstilling, da det kan introducere muligheden      
for deadlocks og nondeterminisme, \fxnote{Er det korrekt?}, for det     
er ikke defineret hvad tiden er hvis det ikke lykkedes at kommunikere   
i det givne tidsskridt. Der findes to muligheder, enten skal \sched     
en signalere at der ikke findes mere arbejde til dette tidsskridt, og   
lade processerne fortsætte i samme tidsskridt. Alternativt skal tiden  
tælles op til næste event, hvorefter processerne signaleres med at    
kommunkationen ikke lykkedes.                                           

\subsubsection{Timeout i samme tidsskridt} Hvis man vælger at
processerne skal signaleres i samme tidsskridt, vil en timeout
efterligne en SKIP guard, men hvor en alternation med en SKIP guard med
det samme kan fortsætte vil en timeout kræve at der blev ventet indtil
der ikke var flere processer der kunne processeres i samme tidsskridt.
Når der ikke er flere processer at vælge imellem skal de ventende
processer fortsætte. Her er muligheden enten at signalere hver proces
en af gangen, og lade den fortsætte inden næste proces signaleres,
eller alternativt, samtidigt at signalerer alle de ventende processerne.

Ved at signalere samtlige processer indføres muligheden for en
livelock. Dette sker hvis to eller flere processer er synkroniseret i
den samme tidsrytme. Et eksempel er hvis de alle i samme periode først
ønsker at modtage data, for derefter at sende data. Her vil alle
processerne uden timeouts vente på hinanden i en deadlock, men med en
timeout vil de alle fortsætte samtidigt og indgå i en ny deadlock,
PyCSP vil derfor med timeouts gå fra en deadlock til en livelock. En
livelock er defineret som hvor tilstandenen i ændres men der foregår
ikke reelt arbejde\inline{skal vi introducere begrebet deadlock,
livelock mv.}.

Ved at aktivere en proces ad gangen har denne proces mulighed for i
samme tidsskridt at indgå i kommunikation med en af de andre ventende
processer. Deadlocken kan man dermed løse og man har mulighed for at
undgå livelock problemet, ved samtidig signalering. Ulemperne er at der
skal foretages et valg om hvilke processer der signaleres med timeout,
og dermed har man risikoen for starvation\fxnote{ref?} hvis det er
den/de samme processer der bliver signaleret.

\subsubsection{Timeout i et efterfølgende tidsskridt} Ved at vælge at
en timeout først forekommer i et efterfølgende tidsskridt, har alle
processer haft den maksimale mulighed for at indgå i en kommunikation.
Desuden kan alle processerne signaleres samtidigt, da et alle timeouts
er overskredet. Man skal dog vælge enten at fortolke en timeout i samme
tidskridt som en timeout efter $\epsilon$, hvor $\epsilon$ sættes til
et vilkårligt lille tidsinterval. Da tiden springer i vilkårligt små
tidsskridt i en simuleringen, vil en fast størrelse af $\epsilon$
risikere at påvirke rækkefølgen af events. Alternativt kan man vælge
at lade tiden springe til nærste event, og der signalere alle timeouts.
Begge muligheder har dog implicit det problem at timeout var sat til
0 og ikke til hverken et vilkårligt lille $\epsilon$ eller anden
tidsenhed og man derfor ændrer på fortolkningen af kode.

\subsection{Vores valg}

Timeouts i Timed PyCSP er en af de vigtigste funktioner, da det disse
giver en der ikke er data, mtimeout processen fortsætte tildet under
antagelsen af problemer.

når tiden er tidspunkt til for et findes der allerede \inline{vi skal
kunne angive at vi ønsker at kommunikere men KUN i det tidsskridt vi er
i, og at hvis dette ikke kan lade sig gøre skal vi breake noget alla at
have en timeout på 0}



\section{Eksempel}
\inline{Beskrivelse af eksemplet og hvordan det er relateret til problemet/modellen. Beskrivelse af løsning uden vores tid}


\subsection{Hajer og fisk på Wator} Som et eksempel på en \des har vi valgt at 
tage  udgangspunkt i det scenarie som \citeauthor{wator}
beskrev i artiklen \citetitle{wator}\cite{wator}. \fxnote{google:lotka,  voltarre} Artiklen beskriver den
fiktive planet Wator, der har form som en torus og er fuldstændig
dækket af vand. Verdenen er inddelt i felter, som kan være tomme, indeholde en
fisk eller en haj\cite[20]{wator}. Følgende karakteristika beskriver fisk og hajers
opførsel.

\begin{itemize}
\item[\textbf{Fisk}]
Lever af plankton, en ressource som er uendelig. Hvis der er ét ledigt 
tilstødende felt, bevæger den sig til dette felt. Hvis der er flere ledige 
felter vælges et tilfældigt. Såfremt en fisk overlever 3 tidsskridt forplanter 
den sig.
\item[\textbf{Hajer}]
Såfremt der er fisk i et eller flere tilstødende felter, vil hajen bevæge sig 
til et af disse felter og spise fisken. Hvis der er ikke er nogen fisk i et af 
disse felter flytter hajen sig til et tilfældigt valgt ledigt felt. Hvis en haj 
ikke spiser i 3 tidsskridt dør den. Overlever den i 10 tidsskridt forplanter 
den sig.
\end{itemize}

For hvert tidsskridt vil alle fisk og hajer udføre en handling ud fra
ovenstående opførsel.
Til at initiere systemet skal der defineres en størrelse af verdenen,
samt hvor mange fisk og hajer der er til stede fra start. Disse fisk og
hajer placeres tilfældigt i verdenen.
Såfremt de initielle parametre for antal fisk og hajer understøtter en 
bæredygtig bestand forventer vi at se bestanden af henholdsvis fisk og hajer 
oscillerer afhængigt af hinanden.

Vi har valgt dette eksempel, da det er enkelt og let forståeligt, men samtidig 
introducerer problemstillinger omkring synkronisering når det paralleliseres.  
Disse problemstillinger optræder fordi en opdatering af hvert felt er afhængigt 
af de omkringliggende felter, og vil derfor være afhængig af felter fra andre 
processer i grænsetilfælde. Ud over at være afhængig af information fra andre 
processer, kan en opdatering også påvirke data hos andre processer.   

\subsubsection{Før introduktion af et tidsbegreb i \csp} For at simulere Wator 
verdenen i et \csp-system hvori tidsbegrebet ikke er introduceret, er vi nødt 
til at udføre en synkronisering af de enkelte processers arbejde. Denne 
synkronisering kan ske ved brug af barrierer, hvor alle processer udfører en 
handling og mødes i barrieren før de fortsætter.

Vi har valgt at basere vores model på \citetitle{crew}\cite{crew}\fxnote{Brian: 
Hvad er din holdning til litteraturhenvisninger.}, hvor verdenen repræsenteres 
som en delt datastruktur og adgangen til denne styres med barrierer. I vores 
model er hver proces derved ansvarlig for en del af verdenen og tilgangen til 
den delte datastruktur sker ud fra CREW-princippet (Concurrent Read, Exclusive 
Write)\cite[5]{crew}, der styres vha. barrierer.  

I en mere ren \csp-model ville man foretage en direkte udveksling af data mellem 
processerne, og undgå den delte datastruktur vi har i vores model.  Vi har 
valgt denne model frem for den mere rene \csp model, da den klarlægger brugen af 
barrierer bedre.  Det bliver meget eksplicit i koden hvornår hvilke dele 
opdateres, og hvornår processerne venter i en barriere.

Vi deler verdenen lodret, hvor hver proces styrer en verdensdel. Hver proces 
gennemgår sin verdensdel og udfører en mulig handling for hver fisk og haj, dog 
vil fisk og hajer i de sidste to kolonner i hver verdensdel ikke bliver 
opdateret på nuværende tidspunkt. Dette skyldes at der kan opstå en en race 
condition hvis disse to kolonner opdateres samtidig med de andre. Årsagen til 
dette er at både processen der er ansvarlig for kolonnerne, og processen 
umiddelbart til højre for den skal have mulighed for at flytte fisk og hajer 
ind i dette område. Hvis der i samme tidsskridt er mulighed for at flytte dem 
ud af området, vil opførslen afhænge af hvad der sker først.  Når denne 
opdatering er fuldført mødes processerne i en barriere, hvorefter hver proces 
opdaterer de to sidste kolonner. Herefter mødes processerne igen i barrieren, 
og når alle kolonner er opdateret kan der foretages en visualisering af de 
udførte opdateringer. Til slut mødes alle i en barriere igen før processerne 
kan begynde en ny iteration.

En repræsentation af opdelingen ses på \cref{fig:wator}. Her er verdenen 
opdelt mellem to processer, og de to kolonner mellem hver del opdateres i et 
separat tidsskridt.  

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.75]{images/wator}
  \caption{Opdeling af verdenen mellem to processer. Der er for hver verdensdel 
  to kolonner som opdateres i et separat tidsskridt.}
  \label{fig:wator}
  \end{center}
\end{figure}


\begin{figure}[hbtp]
\begin{minipage}{\linewidth}
\begin{lstlisting}[label=code:wator-worldpart,caption=Uddrag af processen 
  \code{worldpart} i Wator]
  @proces
  def worldpart (part_id, barR, barW):
  
  ...
  
    while True:
      #Calc your world part:
      main_iteration()
      barW(1)
      barR()
      #Update the two shadowcolumns
      for i in range(world_height):
        for j in range(2):
          element_iteration(Point(right_shadow_col+j,i))
      barW(1)
      barR()
      #visualize have single access
      barW(1)
      barR()
\end{lstlisting}

\begin{lstlisting}[label=code:wator-visualize,caption=Processen 
  \emph{visualize} i Wator]
@proces
 def visualize(barR,barW):
   for i in xrange(iterations):
     barW(1)
     barR()
     barW(1)
     barR()
     pygame.display.flip()
     barW(1)
     barR()
   poison(barW,barR)
\end{lstlisting}

\end{minipage}
\caption[test]{\code{barW(1)} og \code{barR()} er henholdsvis skrivning og læsning til og 
fra en barriere som defineret i \nref{sec:barrierer}.}
\end{figure}
Afviklingen af programmet sker ved at et antal worldpart-, en 
visualize- og en barrier-proces køres parallelt. Af 
\autoref{code:wator-worldpart} og \pageref{code:wator-visualize}\fixme{ændrer pageref til vref i final}, ses det 
overordnede design af henholdsvis worldpart- og 
vizualize-processen.  Værd at bemærke er det store antal barrierekald i 
visualizeprocessen. Dette er til for at man kan benytte den samme barriere som 
wordpartprocessen. Alternativt kunne man have to barriereprocesser; en til 
synkronisering af worldpart med vizualize, samt en som 
worldpart-processerne brugte til synkroniseringen af opdatering af 
verdensdelen og de to sidste kolonner.\inline{hvad skal emphs og hvad skal med stå med code} 

\inline{konklusion hvordan var det at implementere og hvor stor parallelitet 
kan man opnå. }


\subsection{Kunder i en bank}\label{bank-eksempel}
Et klassisk eksempel inden for \des er at simulere  en række kunder der alle 
ankommer til en butik, hvor de skal serviceres. Dette simple problem kan 
udvides til at modellere mange forskellige problemstillinger, der berører 
hvordan flowet ændrer sig hvis man varier en eller flere parametre
i systemet. Programmeringssproget \simpy\fxnote{ref}har, som et af deres 
eksempler, en simulering af kunder i en bank. \simpy bruger dette som et 
gennemgående eksempel, hvor de løbende udvider modellen, for at vise 
forskellige egenskaber ved \simpy. For at kunne sammenligne \simpy  med vores 
implementering af logisk tid, vil vi implementere to af eksemplerne med kunder 
i en bank i \pycsp.

I det simple tilfælde af eksemplet ankommer kunderne til banken på 
tilfældige tidspunkter.  De opholder sig i banken i et tilfældigt 
tidsrum, hvorefter de igen forlader banken. I dette eksempel kan der ikke 
uddrages meget information, men det viser hvordan en simpel model er opbygget i 
hhv.  \simpy og \pycsp for at håndtere tid.

I det andet eksempel er modellen udvidet med en servicedisk. Her skal alle 
kunderne betjenes af en servicemedarbejder, som kun kan ekspederes en kunde ad 
gangen. Alle kunder ankommer igen til banken i tilfældig orden og stiller sig i 
kø for at blive serviceret. Dette  svare til en M/M/1\fxerror{hvad  er en m/m/1 
kø} kø. Det er igen et tilfældigt tidsrum som kunden bruger på at blive 
serviceret.  Dette er stadigt en meget simpel model, men med introduktionen af 
en begrænset ressource kan man uddrage information om den tilhørende kø, f.eks. 
kan der måles hvor lang det tager for hver kunde at blive betjent af 
servicemedarbejdere, samt hvordan køen opfører sig over tid. 

\subsubsection{Før introduktion af et tidsbegreb i \pycsp}
I \simpy er kunderne en proces og det vil derfor være nærliggende ligeledes at 
modellere eksemplet i \pycsp med kunder som en proces. Dette sker i  \simpy når
generatorfunktionen laver en kunde og lader denne køre parallelt med sig selv.  
\inline{hvorfor?- man kan lave child proces med spawn, der der køre i samme parallel 
kald som dets parent? - Hvorfor er dette ikke god CSP stil at bruge} er standard metoden\fxnote{set fra kodeeksempler}I \pycsp 
modellere mere statiske processer, gerne med en generator- og 
arbejderproces, og lade arbejdet flyttes 
mellem processerne igennem kanaler. I \pycsp modellen fungerer 
generatorprocessen som i \simpy, men vi introducerer en bankproces 
som arbejder, og lader kunderne være arbejdet der flyttes mellem dem. 

Mens \simpy kalder kundeprocessen fra generatoren og lader denne stå for håndteringen af kunden 
og den tid hun befinder sig i banken, kender bankprocessen i \pycsp ikke tid som 
sådan. Bankprocessen skal derfor selv vedligeholde en liste med kunderne, der findes inden i banken og til hver 
tidskridt vide hvilke kunder der skal forlade den. 

Tiden er igen modelleret ved brug af barrierer, se afsnit \cref{sec:barrierer}. I 
stedet for at have de to kald til barrieren som den kræver, lige efter hinanden, lader 
vi bankprocessen gå ind i barrieren i starten af tidsskridtet, og så modtage 
kunder, indtil bankeprocessen modtager det andet kald fra barrieren (se 
\cref{bank-alternation-imp}). Dette er nødvendigt for at lade banken have 
mulighed for at modtage et vilkårligt antal kunder i samme tidsskridt, samt 
vide hvornår der ikke vil komme flere kunder.  Vi kan ræsonnere os frem til at 
barrieren stadig virker efter hensigten ved  simpel indsigt.
For at generatorprocessen kan komme foran med et tidsskridt og sende en kunde i et forkert tidsskridt,
skal den have fuldført begge begge kald til barrieren, mens bankprocessen ikke 
har modtaget et kald fra barrieren. Barrieren vil dog ikke modtage kald fra 
nogle, før den har  kaldt bankprocessen. Derfor må generatorprocessen vente i 
sit første kald til barrieren, indtil banken har modtaget sit kald fra 
barrieren, før den kan sende en ny kunde.
Når bankprocessen har modtaget et kald fra barrieren er den ikke længere villig 
til at modtage kunder, før i det efterfølgende tidsskridt. Vi kan bruge samme 
analogi til at ræsonnere os frem til at bankprocessen ikke kan komme et 
tidsskridt foran generatorfunktionen, og derfor virker barrieren stadigt som 
forventet. 

\begin{lstlisting}[float=hbtp,label=bank-alternation-imp,caption=Modtage en 
  kunde eller barrierekald i Bankprocessen]
while True:
		(g,msg) = Alternation([{
		barrierREADER:None,
    customerREADER:None
    }]).select()
		if g == barrierREADER:
			break
    elif g == customerREADER:
			heappush(customers,(time+msg.waittime,msg))
\end{lstlisting}


I det mere avancerede eksempel hvor kunderne skal tilgå den samme begrænsede 
ressource dannes en kø. Denne kan i \pycsp modeleres på flere måder, afhængigt 
at hvilken proces der skal have ansvaret for at vedligeholde køen. En metode er 
internt i en proces at have en liste af kunder der venter, og lade det være 
processens ansvar at håndtere denne liste som en kø. Processen med ansvaret for køen kan 
så enten være den begrænsede ressource, eller en separat proces hvis eneste 
formål er at vedligeholde køen. For nyligt\footnote{d. 22. december 2009} er 
der i \pycsp blevet introduceret ''buffered channels''\cite{pycsp-r147}, og 
disse kan også bruges som en kø. Dermed kan man modellere sin ressource uden 
hensyntagen til håndtering af køen internt eller vha. andre processer, og blot 
lade processen læse fra kanalen når den er klar. Vi har i dette eksempel valgt 
at lade køen være repræsenteret ved en ''buffered channel'', da denne  kræver 
færrest linjer kode, men den kunne lige så godt være repræsenteret som en liste 
i servicedisk processen.


\subsubsection{Konklusion - evaluering - ?}
Ved at se på  implementeringen af de to eksempler af kunder i en bank sammenholdt med implementeringen i \simpy kan man se at de egner det sig godt til 
simulering, og fra eksemplet kan man se at der findes meget kode til 
vedligeholdes af de interne tidsvariabler, som \simpy ikke har behov for. Det drejer sig 
om kode der sørger for at hver proces kender tiden, samt at den er 
synkroniseret på tværs af processerne. Vi forventer derfor at koden skal kunne 
simplificeres i \pycsp med tid, så det bliver lige så simpelt at implementere som i 
\simpy. 

I \simpy findes begrebet ressource direkte i sproget, som en type og 
servicedisken er blot en instans af denne type, og ressourcen står selv for at 
håndtere køen. I \pycsp modelleres servicedisken som en separat proces, og 
bankprocessen er derfor reduceret til blot at sende kunden videre til 
servicedisken og lade kanalen håndtere køen. En ulempe ved brugen af ''buffered 
channels'' som en kø er, at kanalen har en fast størrelse på sin buffer, som 
angives når kanalen oprettes. Man kan dermed risikere en deadlock ved brug af ''buffered 
channels'' sammen med barrierer. Dette opstår hvis ikke processen i samme 
tidsskridt kan foretage transmissionen og kalde barrieren.
Dette kan løses med en \code{alternation} og \code{skip guard}, men så 
skal bankprocessen håndtere fejlede forsendelser og må nødvendigvis introducere en 
sekundær kø hvilket gør at introduktionen af en ''\code{buffered channel}'' er 
irrelevant. For undgå dette har vi i vores tilfælde valgt blot at 
angive en maksimal størrelse på bufferen som er større end det totale antal 
kunder banken modtager.\inline{husk at m/m/1 køer har uendelig længde, se $http://en.wikipedia.org/wiki/M/M/1\_model$ - kan bruges som argument for at have channels af uelndelig længde}

\section{Design og implementering}
\inline{Beskrivelse af design med udgangspunkt i eksemplet}
Formålet med introduktionen er to ting. Dels ønsker vi at introducere diskret tid som et alternativ til barrierer. Dels ønsker vi med diskret tid at åbne for mulighederne for at kunne foretage simuleringer, hvor man bruger \csp som model for systemet. Med disse ændringer er håbet at vi opnår en model der ligger tætter på intentionen bag \csp og så man kan udfase brugen af barrierer, samt med den underliggende parallelitet i \csp kan udnyttes til at øge hastigheden af de simulere modeller, hvis de er begrænset af beregningskapaciteten.
    
Der findes et åbenlyst problem med introduktionen a \des i \csp, som vi kort berørte i \cref{sec:barrierer}. Dette er at \csp er lavet med henblik på at processer arbejder samtidigt og uafhængigt af hinanden, hvor \des  ikke er parallelt, men schedulere sine begivenheder lineært efter hvornår de sker og så kronologisk \fxnote{Dette skal vidst i teori}løber begivenhederne igennem, til der enten ikke er flere begivenheder eller tiden når et vidst punkt. Alternativet til  \des  er \pdes hvor processerne kan have at tiden løbe uafhængigt af hinanden. Dette introducere muligheden for større parallelitet, men samtidigt risikerer processerne ved kommunikation at modtage beskeder fra fortiden, som der skal tages hånd om, f.eks. ved at rulle tiden tilbage. Det har der vidst sig at omkostningerne ved at lade tiden kører parallelt er omkostningerne større end ved at holde tiden synkront på tværs af processerne.
    
\subsection{\pycsp versioner}I \pycsp findes der tre versioner der implementerer \csp: \emph{Process, threads, greenlets}\cite{Friborg2009}. Muligheden for at introducere \des, i de forskellige versioner afhænger af hvordan processerne styres, og dermed hvordan \des kan  implementeres i de forskellige versioner. I proces og threads versionen af \pycsp styres processerne af operativsystemet uafhængig af hinanden \fxnote{ref?}. Dette medfører at \pycsp ikke fra et central område har mulighed for at diktere tiden og om nødvendigt få processer til at vente på hinanden. I greenlets køres processerne derimod på bruger-niveau. Dette betyder at kun en proces kan køre af gangen, og denne kan fortsætte sin kørsel indtil den frivilligt afgiver kontrollen. For at koordinere kørslen af processerne findes der i greenlets en central scheduler der har styr på hvilke processer der er klar til at blive eksekveret og hvilke der venter. Når en proces afgiver kontrollen tager scheduleren over og udvælger den næste proces der skal eksekveres. Denne koordinering i greenlets  egner sig utrolig godt til introduktionen af \des modsat process og threads modellen, hvor der skal ændres betydeligt i den underliggende kode for at kunne koordinere processerne imellem. 

Med den store forskel på de underliggende implementeringer af \csp kan vi ikke gøre os håb om at introducere \des som en pakke, man kan vælge at bruge uafhængigt af hvilken \pycsp-version  der bruges. \Des vil derimod være en en ny version af \pycsp, der ligger sig op ad greenletversionen. 

\subsection{Kodestruktur}  Efter at have valgt at udvider greenletversionen skal vi vælge hvordan vi ønsker at videreudvikle koden. Vi forventer at kunne bruge store dele af koden fra greenletversionen, og kun foretage udvidelser på enkle afgrænsede områder. Desuden ønsker vi at isolere vores ændringer fra den originale greenletversion. Med denne isolation forventer vi at hvis/når der sker stilrettelser af greenletversionen af \pycsp vil man ikke skulle foretage de samme stilrettelser i \des-versionen. 
Rent praktisk opnår vi isolationen mellem \des- og greenletversionen ved nedarvning. 

Hvert af de tre moduler har sin egen mappe i pycsp og i hver af disse findes en tilhørende \code{\_\_init\_\_.py} fil, der fungere som et manifest for den givne version\fxnote*{slet?}{, og som dikterer hvilke filer indeholder hvilke funktioner}. Vi opretter vores eget modul kaldet simulation, og opretter en tilhørende mappe på samme niveau som de andre versioner og med sin egen manifestfil. Manifestfilen kan nu bruges til at udvælge de funktioner der skal tages direkte fra greenletversionen i og hvilke funktioner der skal udvides og som derfor vil ligge i den nye mappe.

\begin{lstlisting}[float=hbtp,label=fig:init,caption=Uddrag af \code{\_\_init\_\_.py} for simulationsversionen.]
from guard import Timeout, Skip
from pycsp.greenlets.alternation import choice
from alternation import Alternation
from pycsp.greenlets.channel import ChannelPoisonException, ChannelRetireException
\end{lstlisting}

I \cref{fig:init} kan man se at funktionerne \code{choice, ChannelPoisonException} og \code{ChannelRetireException} alle bliver hentet fra greenletmodulet, mens at funktionerne \code{Timeout, Skip} og \code{Alternation} bliver importeret fra samme mappe, og derfor er en modificeret version. For slutbrugeren  vil dette dog være transparent, og hun vil blot se simulationversionen som en selvstændig version på lige fod med de andre tre versioner.


\input{chapters/time-implementation} 
   \fxnote{Hvordan skal events gemmes}
    
  \section{Evaluering}
    \inline{Evaluering af hvordan eksemplet løses efter den valgte 
    implementering benyttes. Inkluderer test+performance}
  \section{Fremtidigt arbejde}
  \section{Opsummering}
