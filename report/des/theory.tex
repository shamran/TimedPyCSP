\section{Beskrivelse/teori} \label{sec:des-teori}
\inline{Beskrivelse af tidsmodellen, teorien omkring den og hvor/hvad den 
    benyttes til. Teori: henvisning til litteratur, bl.a.  matematik/beviser 
    for modellen}
\inline{Noget med hvilke funktion der er krævet. (Kun en Wait og en Now)}

\begin{shaded}
\fxnote{Gennemlæses og højst sandlysningt omskrives med henblik på sammenhæng og mangler.}
Indenfor simulering er \des en meget brugt metode til at modellere systemer. I 
\des anskues tid som diskrete tidsskridt som er uden kobling til realtid. I 
disse tidsskridt udføres en eller flere begivenheder, som ved afslutning kan 
føre det modellerede system over i en ny tilstand, og herved et nyt tidsskridt. 
Det er irrelevant hvor lang tid det tager at udføre en begivenhed målt i 
realtid, da der først sker en overgang til en ny tilstand når alle begivenheder 
for et givet diskret tidsskridt er udført. Dette er årsagen til at der ikke er 
nogen kobling mellem den diskrete tid og realtid, og et diskret tidsskridt kan 
variere arbitrært i realtid. Begivenhederne der skal udføres af systemet kan 
enten være givet på forhånd, eller blive skemaplanlagt dynamisk under afviklingen 
af andre begivenheder. 
Afhængig af hvad der simuleres, kan man udtrække relevant information om systemet, f.eks. gennemsnitlig behandlingstid for elementer, længden af køer i systemet, og den samlede aktivitetstid for hvert delelement i systemet. \inline{omskriv med henblik på tilstand}


For at kunne konstruere en \des skal vi have følgende til rådighed; En repræsentation af tid til at styre hvornår vi skifter tidsskridt, en liste over begivenheder der skal udføres i hvert tidsskridt, samt mulighed for at opsamle statistisk data fra simulationen. 

    
I \csp har vi garanti for at de eneste afhængigheder mellem processer vil være kommunikation. I \des har vi ud over kommunikation også en afhængighed af at synkronisere tiden mellem processerne.En simulering løber begivenhederne kronologisk igennem til der enten ikke er flere begivenheder eller som det oftere er tilfældet til simuleringen når et forud defineret tidspunkt.

\fxnote*[inline,nomargin]{Brian: ok brug af parallelitet}{Alternativet til  \des  er \pdes hvor tiden i processerne kan løbe uafhængigt af hinanden. Dette introducerer muligheden for større parallitet, men samtidigt risikerer processerne ved kommunikation at modtage beskeder fra fortiden, som der skal tages hånd om, f.eks. ved at rulle tiden tilbage. \pdes har vundet stort indpas i den videnskabelig verden som man kan se af \cref{tab:des}, en grund til dette er at ved at lade tiden kører parallelt er omkostningerne større end ved at holde tiden synkront på tværs af processerne.}
\end{shaded}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrr}
	\toprule
	\mc{Periode} & \mc{DES} & \mc{PDES}\\
	\midrule
1970 til 1980 &   296 &2\\
1980 til 1990 & 1.460 &95\\
1990 til 2000 & 6.190 &1.260\\
2000 til 2010 &13.100 &1.210\\
\bottomrule
	\end{tabular}
	\caption{Publisering af artikler if. google scholar ved søgning på hhv. ''\des'' og ''parallel \des''}
	\label{tab:des}
\end{table}
\subsection*{Noter til afsnittet}
\begin{itemize}
\tightlist
	\item stokastisk varians i relation til M/M/1
	\item Hvad bruges DES til? styrker/svagheder?
	\item Henvis til DE-simulation.ps
\end{itemize}


\subsection{Barrierer} \label{sec:barrierer}
\inline{Hele afsnittet skal skrives om for at få det generelle samlet i starten, og vores specifikke efterfølgende. Evt. have mindre om vores implementation}

I \des findes der  en global tid og alle processerne skal derfor have en fælles tid der tæller op 
samtidigt.  En global viden som tid kræver synkronisering af alle 
processerne, og til denne koordinering og synkronisering af flere 
processer er  den mest brugte metode at introducere en barriere. Barrierer blev først introduceret i MPI\cite{mpi-barrier}, hvor den bruges til at 
sikre at alle tråde venter i barrieren før de kan fortsætte. 

I \csp kan man udnytte at begge 
kanalender skal være klar, før der der kan kommunikeres og at en proces der er 
indgår i en kommunikation vil vente indtil den anden ende er klar før den 
fortsætter.  Ved hjælp af kanaler kan man derfor lave en simpel barriere 
trivielt ved brug af kommunikation over kanaler.  En implementering af en 
barriere som en selvstændig proces kan eksempelvis implementeres som i 
\cref{barrier-imp}.

\begin{lstlisting}[float, label=barrier-imp,caption=En barriere i \pycsp]
@proces
def Barrier(nprocesses, signalIN, signalOUT):
	while True:
		for i in range (nprocesses):
			signalIN()
		for i in range (nprocesses):
			signalOUT(0)
\end{lstlisting}

Denne implementering af en barriere kræver, i modsætning til de fleste andre 
implementeringer af barrierer\cites{mpi-barrier, crew}, to kald. Det første 
sender en variabel til barriereprocessen, mens,
det andet kald modtager en dummyværdi fra barriereprocessen. Det kræver derved 
to kanaler at implementere barrieren. På den ene kanal er barrieren den eneste 
der læser værdierne; en besked sendt på denne kanal vil derfor altid modtages 
af barrieren. På den anden kanal er barrieren den eneste der skriver, og en 
modtaget besked må derfor komme fra barrieren.

Vi kan overbevise os om korrektheden af barrieren, da alle processerne først 
går ind i barrieren ved at sende en værdi til barrieren. Hvis barrieren ikke er 
klar, sikrer \csp at processerne venter indtil barrieren er klar til at modtage 
værdierne. Først når barrieren har modtaget en værdi fra alle processerne, 
begynder barrieren at sende sin værdi, og det er først når en proces modtager 
denne værdi fra barrieren at den må fortsætte. Når en proces modtager værdien 
fra barrieren fortsætter den og man kan risikere at den ønsker at gå ind i 
barrieren inden denne har sendt sin værdi til alle processer for at frigive dem.
Processer der ønsker adgang til barrieren vil da gå i stå, idet de prøver at 
sende til barrieren før den er klar til at modtage. Først 
når barrieren har signaleret til alle processer at de må fortsætte, læser den 
på kanalen for at accepterer processer der ønsker at tilgå barrieren. Det er 
denne egenskab fra \csp der giver os garanti for at en proces der netop er 
frigivet fra barrieren ikke går ind i den igen og derved risikerer at komme 
foran. 

En ulempe ved denne simple barriere er at antallet af processer skal være 
konstant gennem hele kørslen.
Vi vil senere se på et bankeksempel hvor dette problem opstår (\cref{bank-eksempel}). Her ville nogle af 
processerne kunne slutte tidligt, men må fortsætte med  at kalde barrieren, indtil alle processerne er klar til at slutte.
Man kunne ændrer barriereprocessen, så man dynamisk kan ændre på antallet af processer der 
skal synkroniseres. I de fleste implementationer af barrier er dette en mulighed, men til vores simple illustration, har vi valgt ikke at implementere det.

Barrierer er en meget effektiv metode til at synkronisere processer der kører 
parallelt, og er brugt flittigt i MPI. I \csp er der dog en konflikt i brugen 
af barrierer da hver proces fungerer i isolation, og den eneste interaktion der 
skal være mellem processerne er når der kommunikeres via kanalerne. 
Introduktionen af barrierer og kald til disse virker derfor kunstig i \csp. 
\citeauthor{crew} beskriver brugen af barrierer som:

\mycite[1]{crew}{
\begin{otherlanguage}{english}
[\ldots] where the barriers may be used to maintain global and/or localised models of time and to synchronise safe access to shared data [\ldots]
\end{otherlanguage}
}

Barrierens berettigelse er derfor for at kunne introducere tid, samt for at kunne bruge delt data. I \csp bør der ikke være delt data mellem processerne, men derimod kun  lokalt data. Hvis der er data er delt pga. arkitekturen \csp er implementeret på, bør dette abstraheres væk men udnyttes internt i kanalerne. At introducere hjælpemidler for styre delt data, er derfor at tilskynde til en forkert brug af \csp. Tiden er den anden begrundelse for at benytte barrierer.
Men barrierer giver kun en  primitiv model for tid, og vi vil vise at med brugen af en \des får man et stærkere værktøj, der blandt meget andet også kan erstatte brugen af barrierer.


\section{Timeout} 
\inline{kausal tid.}
\inline{timeout, wake-first - wake-last, edge-triggering indenfor logik}
\begin{shaded}
Med et diskret simuleringsmiljø kan man forstille sig tre forskellige scenarier for  hvornår  en proces er villig
til at kommunikere. En proces ønsker at kommunikere  frem til et givent tidspunkt; processen ønsker kommunikation fra et givent tidspunkt; og endeligt ønsker processen at kommunikere på et specifikt tidspunkt.
At ville kommunikere fra et given tidspunkt i fremtiden, svare til at   
vente uden at lave noget indtil det givne tidspunkt for så at kommunikere. Hvilket ikke medfører nogle problemer. Det medfører heller ikke  designmæssig udfordring at kommunikere ud til et tidspunkt i fremtiden.

For processer der kun ønsker at kommunikere til et given tidspunkt,
medføres derimod et designvalg, da det ikke er defineret hvordan simuleringen skal forholde sig hvis det ikke lykkedes at kommunikere   
i det givne tidsskridt. Der findes to muligheder, enten skal \sched     
en signalere at der ikke findes mere arbejde til dette tidsskridt, og   
lade processerne fortsætte i samme tidsskridt. Alternativt skal tiden   
tælles op til næste begivenhed, hvorefter processerne aktiveres med besked om  at    
kommunikationen ikke lykkedes. 
\subsubsection{Timeout i samme tidsskridt} 
Hvis man vælger at processerne skal aktiveres i samme tidsskridt, vil en timeout
efterligne en SKIP guard, men hvor en alternation med en SKIP guard med
det samme kan fortsætte vil en timeout kræve at der blev ventet indtil
der ikke var flere processer der kunne processers i samme tidsskridt.
Når der ikke er flere processer at vælge imellem skal de ventende
processer fortsætte. Her er muligheden enten at aktivere hver proces
en af gangen, og lade den fortsætte inden næste proces aktiveres,
eller alternativt, samtidigt at aktiverer alle de ventende processerne.

Ved at aktivere samtlige processer indføres muligheden for en
livelock. Dette sker hvis to eller flere processer er synkroniseret i
den samme tidsrytme. Et eksempel er hvis de alle i samme periode først
ønsker at modtage data, for derefter at sende data. Her vil alle
processerne uden timeouts vente på hinanden i en deadlock, men med en
timeout vil de alle fortsætte samtidigt og indgå i en ny deadlock,
\pycsp vil derfor gå fra en deadlock til en livelock. 

Ved at aktivere en proces ad gangen har denne proces mulighed for i
samme tidsskridt at indgå i kommunikation med en af de andre ventende
processer. Deadlocken kan man dermed løse og man har mulighed for at
undgå livelock problemet, som set ved samtidig signalering. Ulemperne er at der
foretages et valg om i hvilken rækkefølge  processer aktiveres med timeout,
og dermed har man risikoen for starvation.


\subsubsection{Timeout i et efterfølgende tidsskridt} 
Ved at vælge at en timeout der først forekommer i et efterfølgende tidsskridt, har alle
processer haft den maksimale mulighed for at indgå i en kommunikation.
Desuden kan alle processerne aktiveres samtidigt, da  alle timeouts
er overskredet. Man kan i dette tilfælde  vælge enten at fortolke en timeout i samme
tidskridt som hvor processen først aktiveres efter $\epsilon$, hvor $\epsilon$ sættes til
et vilkårligt lille tidsinterval. Da tiden springer i vilkårligt små
tidsskridt i en simuleringen, vil en fast størrelse af $\epsilon$
risikere at påvirke rækkefølgen af begivenheder. Alternativt kan man vælge
at lade tiden springe til nærste begivenhed, og der aktivere alle processer.

Begge muligheder har dog grundliggende den svaghed at den oprindelige timeout var sat til
0 og ikke til hverken et vilkårligt lille $\epsilon$ eller anden
tidsenhed og man vil derfor ændrer på fortolkningen af kode. 
\subsubsection{Vores valg}
I PyCSP vil processer der venter i en alternation med en timeout der er overskrevet, blive aktiveret en ad gangen. Dette
medfører at en proces har mulighed for at indgå i kommunikation med en anden proces selvom dens timeout guard er overskredet. \inline{Mere}
\end{shaded}

