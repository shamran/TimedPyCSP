\section{Beskrivelse/teori} \label{sec:des-teori}
\inline{Beskrivelse af tidsmodellen, teorien omkring den og hvor/hvad den 
    benyttes til. Teori: henvisning til litteratur, bl.a.  matematik/beviser 
    for modellen}
\inline{Skal vi skrive noget om at introduktionen af tid er det samme som at introducere prioritet}

\begin{shaded}
\fxnote{Gennemlæses og højst sandlysningt omskrives med henblik på sammenhæng og mangler.}
Indenfor simulering er \des en meget brugt metode til at modellere systemer. I 
\des anskues tid som diskrete tidsskridt som er uden kobling til realtid. I 
disse tidsskridt udføres en eller flere begivenheder, som hver især ændrer på systemets tilstand. Når alle begivenheder for et tidsskridt er udført kan tiden tælles op og begivenheder for det nye tidsskridt kan udføres. Der kan være være planlagt et vilkårligt antal beginvenheder til et tidsskridt og hver begivenhed kan variere vilkårligt med henlik på hvor langt tid den tager at udføre i realtid. Det er disse betingelser der forårsager at der ikke er nogen kobling mellem den diskrete tid og realtid, og et diskret tidsskridt kan derved variere arbitrært i realtid. Begivenhederne der skal udføres af systemet kan enten være givet på forhånd, eller blive skemaplanlagt dynamisk under afviklingen af andre begivenheder. 
Afhængig af hvad der simuleres, kan man udtrække relevant information om systemet, f.eks. gennemsnitlig behandlingstid for elementer, længden af køer i systemet, og den samlede aktivitetstid for hvert delelement i systemet.


For at kunne konstruere en \des skal vi have følgende til rådighed; En repræsentation af tid til at styre hvornår vi skifter tidsskridt, en liste over begivenheder der skal udføres i hvert tidsskridt, samt mulighed for at opsamle statistisk data fra simulationen. 

    
I \csp har vi garanti for at de eneste afhængigheder mellem processer vil være kommunikation. I \des har vi ud over kommunikation også en afhængighed af at synkronisere tiden mellem processerne.En simulering løber begivenhederne kronologisk igennem til der enten ikke er flere begivenheder eller som det oftere er tilfældet til simuleringen når et forud defineret tidspunkt.

\fxnote*[inline,nomargin]{Brian: ok brug af parallelitet}{Alternativet til  \des  er \pdes hvor tiden i processerne kan løbe uafhængigt af hinanden. Dette introducerer muligheden for større parallitet, men samtidigt risikerer processerne ved kommunikation at modtage beskeder fra fortiden, som der skal tages hånd om, f.eks. ved at rulle tiden tilbage. \pdes har ikke vundet stort indpas i den videnskabelig verden som man kan se af \cref{tab:des}, en grund til dette er at når tiden kan køre parallelt vil de deraf følgende omkostningerne resultere i lavere hastighed end ved at holde tiden synkront på tværs af processerne.}
\end{shaded}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrr}
	\toprule
	\mc{Periode} & \mc{DES} & \mc{PDES}\\
	\midrule
1970 til 1980 &   296 &2\\
1980 til 1990 & 1.460 &95\\
1990 til 2000 & 6.190 &1.260\\
2000 til 2010 &13.100 &1.210\\
\bottomrule
	\end{tabular}
	\caption{Publisering af artikler if. google scholar ved søgning på hhv. ''\des'' og ''parallel \des''}
	\label{tab:des}
\end{table}
\subsection*{Noter til afsnittet}
\begin{itemize}
\tightlist
	\item stokastisk varians i relation til M/M/1
	\item Hvad bruges DES til? styrker/svagheder?
	\item Henvis til DE-simulation.ps
\end{itemize}


\subsection{Barrierer} \label{sec:barrierer}
%\inline{Hele afsnittet skal skrives om for at få det generelle samlet i starten, og vores specifikke efterfølgende. Evt. have mindre om vores implementation}

I \des findes der  en global tid og alle processerne skal derfor have en fælles tid der tæller op 
samtidigt.  En global viden som tid kræver synkronisering af alle 
processerne, og til denne koordinering og synkronisering af flere 
processer er  den mest brugte metode at introducere en barriere. Barrierer blev først introduceret i MPI \cite{mpi-barrier}, hvor den bruges til at 
sikre at alle tråde venter i barrieren før de kan fortsætte. 

I \csp kan man lave sin egen barrierer ved at udnytte at begge 
kanalender skal være klar, før der der kan kommunikeres og at en proces der er 
indgår i en kommunikation vil vente indtil den anden ende er klar før den 
fortsætter.  Ved hjælp af kanaler kan man derfor lave en simpel barriere 
trivielt ved brug af kommunikation over kanaler.  En implementering af en 
barriere som en selvstændig proces kan ses i 
\cref{barrier-imp}.

\begin{lstlisting}[float, label=barrier-imp,caption=En barriere i \pycsp]
@proces
def Barrier(nprocesses, signalIN, signalOUT):
	while True:
		for i in range (nprocesses):
			signalIN()
		for i in range (nprocesses):
			signalOUT(0)
\end{lstlisting}
%
%Denne implementering af en barriere kræver, i modsætning til de fleste andre 
%implementeringer af barrierer\cites{mpi-barrier, crew}, to kald. Det første 
%sender en variabel til barriereprocessen, mens,
%det andet kald modtager en dummyværdi fra barriereprocessen. Det kræver derved 
%to kanaler at implementere barrieren. På den ene kanal er barrieren den eneste 
%der læser værdierne; en besked sendt på denne kanal vil derfor altid modtages 
%af barrieren. På den anden kanal er barrieren den eneste der skriver, og en 
%modtaget besked må derfor komme fra barrieren.
%
%Vi kan overbevise os om korrektheden af barrieren, da alle processerne først 
%går ind i barrieren ved at sende en værdi til barrieren. Hvis barrieren ikke er 
%klar, sikrer \csp at processerne venter indtil barrieren er klar til at modtage 
%værdierne. Først når barrieren har modtaget en værdi fra alle processerne, 
%begynder barrieren at sende sin værdi, og det er først når en proces modtager 
%denne værdi fra barrieren at den må fortsætte. Når en proces modtager værdien 
%fra barrieren fortsætter den og man kan risikere at den ønsker at gå ind i 
%barrieren inden denne har sendt sin værdi til alle processer for at frigive dem.
%Processer der ønsker adgang til barrieren vil da gå i stå, idet de prøver at 
%sende til barrieren før den er klar til at modtage. Først 
%når barrieren har signaleret til alle processer at de må fortsætte, læser den 
%på kanalen for at accepterer processer der ønsker at tilgå barrieren. Det er 
%denne egenskab fra \csp der giver os garanti for at en proces der netop er 
%frigivet fra barrieren ikke går ind i den igen og derved risikerer at komme 
%foran. 
%
%En ulempe ved denne simple barriere er at antallet af processer skal være 
%konstant gennem hele kørslen.
%Vi vil senere se på et bankeksempel hvor dette problem opstår (\cref{bank-eksempel}). Her ville nogle af 
%processerne kunne slutte tidligt, men må fortsætte med  at kalde barrieren, indtil alle processerne er klar til at slutte.
%Man kunne ændrer barriereprocessen, så man dynamisk kan ændre på antallet af processer der 
%skal synkroniseres. I de fleste implementationer af barrier er dette en mulighed, men til vores simple illustration, har vi valgt ikke at implementere det.

Barrierer er en meget effektiv metode til at synkronisere processer der kører 
parallelt, og er brugt flittigt i MPI. I \csp er der dog en konflikt i brugen 
af barrierer da hver proces fungerer i isolation, og den eneste interaktion der 
skal være mellem processerne er når der kommunikeres via kanalerne. 
Introduktionen af barrierer og kald til disse virker derfor kunstig i \csp. 
\citeauthor{crew} beskriver brugen af barrierer som:

\mycite[1]{crew}{
\begin{otherlanguage}{english}
[\ldots] where the barriers may be used to maintain global and/or localised models of time and to synchronise safe access to shared data [\ldots]
\end{otherlanguage}
}

Barrierens berettigelse er derfor for at kunne introducere tid, samt for at kunne bruge delt data. I \csp bør der ikke være delt data mellem processerne, men derimod kun  lokalt data. Hvis der er data er delt pga. arkitekturen \csp er implementeret på, bør dette abstraheres væk men udnyttes internt i kanalerne. At introducere hjælpemidler for styre delt data, er derfor at tilskynde til en forkert brug af \csp. Tiden er den anden begrundelse for at benytte barrierer.
Men barrierer giver kun en  primitiv model for tid, og vi vil vise at med brugen af en \des får man et stærkere værktøj, der blandt meget andet også kan erstatte brugen af barrierer.

\subsection{Timeout} 
I den eksisterende \pycsp findes der som nævnt i \cref{sec:csp} en alternation, hvor brugeren har mulighed for at tilknytte to specielle guards. Den ene er en SKIP-guard der giver mulighed for at kommunikere hvis kanalen er klar og ellers fortsætte uden at kommunikere. Den anden er timeout-guarden der udvider SKIP-guarden så man venter på kommunikation en given periode hvorefter man tager SKIP-guarden. 
Med \des ændres tiden så timeout opererer på tidsskridt fremfor en tidsperiode. Dette medfører at en proces kan ønske at kommunikere i indeværende tidsskridt, men ikke i det efterfølgende.
Vi kan dog ikke i tidsskridtet evaluere om kommunikation vil være muligt. Dette skyldes at tiden står stille mens processerne er aktive så selvom kommunikation ikke er muligt på et tidspunkt i tidsskridtet kan en efterfølgende begivenhed i samme tidsskridt muliggøre kommunikation.

En løsningsmodel for at kunne håndtere tidsskridt i timeouts er at lade processerne vente indtil et efterfølgende tidsskridt og så tage SKIP-guarden. Det efterfølgende  tidsskridt kan så  enten kan være et kunstigt lille tidsskridt eller indtil den næste begivnhed der er planlagt.
Hvis tiden springer et lille  tidsskridt frem  i en simuleringen, risikere vi at der findes andre begivnheder der har et mindre tidsskridt og vi  kan derfor  påvirke rækkefølgen af begivenheder der skal eksekveres. 
Alternativt kan man vælge at lade tiden springe til den næste begivenhed der er planlagt og der som det første vælge SKIP-guarden, her vil man ikke risikere at ændre på rækkefølgen, men man risikere derimod at springe langt frem i tiden.
Begge muligheder har dog grundliggende den svaghed at oprindeligt ønskede man kun at kommunikere i det indeværende tidsskridt og ikke i hverken et vilkårligt lille tidsrum eller i et tilfældigt tidsrum frem til en efterfølgende begivnhed.

En anden løsningsmodel er at vente til lige før tiden tælles op, og der kalde de ventende processers SKIP-guard. 
For at kunne adskille hvilke processer der har en begivnhed til et tidsskridt og hvilke der venter på kommunikation kan vi \fxnote*{illustration}{benytte os af edge-triggering} til at dele hver tidsskridt op i to grupper, wake-first og wake-last.
I wake-first gruppen foretages eksekveringen af de processer der har tilknyttet en begivenhed til det givne tidsskridt, mens man i  wake-last gruppen aktiverer SKIP-guarden for de processerne der venter på en timeout.

Edge-triggering er den bedste løsningsmodel af de to beskrevet da man her har mulighed for at eksekvere alle begivnheder som måske resulterer i kommunikation, og først derefter aktivere SKIP-guards, for de processer der har en timeout til samme tidsskridt. Ulempen ved denne metode er at det krævere størrer implementering, da der nu findes to seperate måde at vente for hhv. begivenheder og timeouts.

